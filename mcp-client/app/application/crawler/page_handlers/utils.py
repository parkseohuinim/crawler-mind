"""
Page Handlers ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

URL ë³€í™˜, íŒŒì¼ëª… ì •ì œ, ë‚ ì§œ í¬ë§·íŒ… ë“± ê³µìš© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
import re
from datetime import datetime
from typing import Optional, Tuple
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

logger = logging.getLogger(__name__)

# ê¸€ë¡œë²Œ íƒ€ì„ìŠ¤íƒ¬í”„ ë³€ìˆ˜
CURRENT_TIMESTAMP: Optional[str] = None


def set_current_timestamp(timestamp_str: Optional[str]) -> None:
    """íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì •"""
    global CURRENT_TIMESTAMP
    if timestamp_str is not None:
        CURRENT_TIMESTAMP = timestamp_str
    else:
        CURRENT_TIMESTAMP = None


def get_current_timestamp() -> str:
    """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)"""
    global CURRENT_TIMESTAMP
    if CURRENT_TIMESTAMP is None:
        CURRENT_TIMESTAMP = datetime.now().strftime('%Y-%m-%d_%H%M%S')
        logger.info(f"ğŸ• ìƒˆë¡œìš´ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±: {CURRENT_TIMESTAMP}")
    return CURRENT_TIMESTAMP


def sanitize_filename(filename: str, max_length: int = 100) -> str:
    """
    íŒŒì¼ëª…ì„ ì•ˆì „í•˜ê³  ê°€ë…ì„± ìˆê²Œ ë³€í™˜
    
    Args:
        filename: ì›ë³¸ íŒŒì¼ëª…
        max_length: ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸ê°’: 100)
    
    Returns:
        str: ë³€í™˜ëœ ì•ˆì „í•œ íŒŒì¼ëª…
    """
    # 1. ì¹´í…Œê³ ë¦¬ íƒœê·¸ ì²˜ë¦¬: [ê³µì§€] â†’ (ê³µì§€)
    sanitized = re.sub(r'\[([^]]+)\]', r'(\1)', filename)
    
    # 2. ì‹œê°„ í‘œê¸° ê°œì„ : 03/12(ìˆ˜) 01:00 ~ 08:00 â†’ 0312ìˆ˜(0100-0800)
    datetime_pattern = r'(\d{1,2})/(\d{1,2})\(([^)]+)\)\s*(\d{1,2}):(\d{2})\s*~\s*(\d{1,2}):(\d{2})'
    datetime_match = re.search(datetime_pattern, sanitized)
    if datetime_match:
        month, day, weekday, start_hour, start_min, end_hour, end_min = datetime_match.groups()
        time_str = f"{month.zfill(2)}{day.zfill(2)}{weekday}({start_hour.zfill(2)}{start_min}-{end_hour.zfill(2)}{end_min})"
        sanitized = re.sub(datetime_pattern, time_str, sanitized)
    
    # 3. ê¸°íƒ€ ì‹œê°„ íŒ¨í„´ë“¤ ì²˜ë¦¬
    # HH:MM í˜•ì‹ â†’ HHMM
    sanitized = re.sub(r'(\d{1,2}):(\d{2})', r'\1\2', sanitized)
    
    # MM/DD í˜•ì‹ â†’ MMDD
    sanitized = re.sub(r'(\d{1,2})/(\d{1,2})', r'\1\2', sanitized)
    
    # 4. íŠ¹ìˆ˜ë¬¸ìë¥¼ ì˜ë¯¸ ìˆê²Œ ë³€í™˜
    # ~ (ë¬¼ê²°í‘œ) â†’ to
    sanitized = re.sub(r'\s*~\s*', 'to', sanitized)
    
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    sanitized = re.sub(r'\s+', ' ', sanitized)
    
    # 5. ê¸¸ì´ ì œí•œ
    if len(sanitized) > max_length:
        sanitized = sanitized[:max_length]
    
    # 6. íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    sanitized = re.sub(r'[<>:"/\\|?*]', '', sanitized)
    
    return sanitized.strip()


def to_mshop_url(url: str) -> str:
    """KT Shop PC URLì„ ëª¨ë°”ì¼(https://m.shop.kt.com:444) í˜•íƒœë¡œ ë³€í™˜"""
    if not url or not url.startswith('http'):
        return ''
    return url.replace('https://shop.kt.com', 'https://m.shop.kt.com:444/m')


def to_mglobalroaming_url(url: str) -> str:
    """ê¸€ë¡œë²Œë¡œë° PC URLì„ ëª¨ë°”ì¼(https://m.globalroaming.kt.com) í˜•íƒœë¡œ ë³€í™˜"""
    if not url or not url.startswith('http'):
        return ''

    parsed = urlparse(url)
    query_params = parse_qs(parsed.query)
    mobile_netloc = parsed.netloc.replace('globalroaming.kt.com', 'm.globalroaming.kt.com')

    if parsed.path.startswith('/news/view.asp'):
        idx_val = query_params.get('idx', [''])[0]
        mobile_path = '/news/view.asp'
        mobile_query = urlencode({'idx': idx_val})
        return urlunparse((parsed.scheme, mobile_netloc, mobile_path, '', mobile_query, ''))

    return urlunparse((parsed.scheme, mobile_netloc, parsed.path, parsed.params, parsed.query, parsed.fragment))


def to_gigagenie_murl(url: str) -> str:
    """ê¸°ê°€ì§€ë‹ˆ ë¸”ë¡œê·¸ PC URLì„ ëª¨ë°”ì¼(https://gigagenie.kt.com/m/blog) í˜•íƒœë¡œ ë³€í™˜"""
    if not url or not url.startswith('http'):
        return ''
    return url.replace('https://gigagenie.kt.com/blog/', 'https://gigagenie.kt.com/m/blog/')


def format_date_show(date_str: str) -> str:
    """ê³µì—°ì˜ˆë§¤ ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
    if not date_str:
        return ""
    
    patterns = [
        (r'(\d{4})\.(\d{1,2})\.(\d{1,2})', r'\1-\2-\3'),
        (r'(\d{4})-(\d{1,2})-(\d{1,2})', r'\1-\2-\3'),
        (r'(\d{1,2})/(\d{1,2})/(\d{4})', r'\3-\1-\2'),
    ]
    
    for pattern, replacement in patterns:
        match = re.search(pattern, date_str)
        if match:
            return re.sub(pattern, replacement, date_str)
    
    return date_str


def format_content(content: str) -> str:
    """ì½˜í…ì¸  í¬ë§·íŒ…"""
    if not content:
        return ""
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
    content = re.sub(r'^\s+|\s+$', '', content, flags=re.MULTILINE)
    
    return content


def create_markdown(title: str, date: str, content: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±"""
    return f"""# {title}

**ë‚ ì§œ:** {date}

---

{content}
"""


async def smart_goto(
    page,
    url: str,
    wait_for_selector: Optional[str] = None,
    timeout: int = 60000,
    selector_timeout: int = 100000,
    extra_wait: int = 6000
):
    """
    íš¨ìœ¨ì ì¸ í˜ì´ì§€ ë¡œë“œ í•¨ìˆ˜
    
    - domcontentloadedë¡œ ë¹ ë¥´ê²Œ ë¡œë“œ
    - í•„ìš”í•œ ìš”ì†Œë§Œ ì¶”ê°€ ëŒ€ê¸° (ì—†ìœ¼ë©´ skip)
    - ë¶ˆí•„ìš”í•œ networkidle ëŒ€ê¸° ì—†ìŒ
    
    Args:
        page: Playwright page ê°ì²´
        url: ì ‘ì†í•  URL
        wait_for_selector: ëŒ€ê¸°í•  CSS selector (optional)
        timeout: goto íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 30ì´ˆ)
        selector_timeout: selector ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 10ì´ˆ)
        extra_wait: ì¶”ê°€ ë Œë”ë§ ëŒ€ê¸° (ê¸°ë³¸ 1.5ì´ˆ)
    
    Returns:
        response: Playwright Response ê°ì²´
    """
    # 1ë‹¨ê³„: ë¹ ë¥¸ DOM ë¡œë“œ
    response = await page.goto(url, wait_until='domcontentloaded', timeout=timeout)
    
    # 2ë‹¨ê³„: í•„ìš”í•œ ìš”ì†Œ ëŒ€ê¸° (ìˆìœ¼ë©´ ì¦‰ì‹œ ì§„í–‰, ì—†ìœ¼ë©´ skip)
    if wait_for_selector:
        try:
            await page.wait_for_selector(wait_for_selector, timeout=selector_timeout)
        except Exception:
            logger.debug(f"ğŸ” Selector not found, continuing: {wait_for_selector}")
    
    # 3ë‹¨ê³„: JS ë Œë”ë§ ë²„í¼
    if extra_wait > 0:
        await page.wait_for_timeout(extra_wait)
    
    return response


async def smart_goto_with_status(
    page,
    url: str,
    wait_for_selector: Optional[str] = None,
    timeout: int = 30000,
    selector_timeout: int = 10000,
    extra_wait: int = 1500
):
    """
    smart_goto + HTTP ìƒíƒœ ì½”ë“œ ë¡œê¹…
    
    Returns:
        tuple: (response, status_code)
    """
    response = await smart_goto(
        page, url, 
        wait_for_selector=wait_for_selector,
        timeout=timeout,
        selector_timeout=selector_timeout,
        extra_wait=extra_wait
    )
    
    status_code = response.status if response else None
    
    if status_code:
        if status_code >= 400:
            logger.error(f"âŒ HTTP {status_code}: {url}")
        elif status_code >= 300:
            logger.warning(f"âš ï¸ HTTP {status_code} redirect: {url}")
    
    return response, status_code




