"""
KT ÏÉÅÌíàÏÇ¨Ï†Ñ(wDic) Ìï∏Îì§Îü¨

ÏÉÅÌíà ÏÉÅÏÑ∏ Î∞è Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù ÌéòÏù¥ÏßÄ Ï≤òÎ¶¨
"""

import asyncio
import logging
import re
from typing import Any, Dict, List, Optional
from urllib.parse import urljoin

from playwright.async_api import async_playwright
from markdownify import markdownify as md

from ..handler_registry import register_page_handler

logger = logging.getLogger(__name__)


def _to_murl(u: str) -> str:
    """PC URLÏùÑ Î™®Î∞îÏùº URLÎ°ú Î≥ÄÌôò"""
    if not u or not u.startswith('http'):
        return ''
    m = u.replace('https://product.kt.com', 'https://m.product.kt.com')
    m = m.replace('/wDic/', '/mDic/')
    return m


async def handle_product_detail(
    url: str, 
    fclient: Any = None, 
    menu: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """
    ÏÉÅÌíà ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄ Ï≤òÎ¶¨ Ìï∏Îì§Îü¨
    """
    logger.info(f"üîó Product detail: {url}")
    
    m = re.search(r'ItemCode=(\d+)', url)
    if not m:
        return None
    
    item_code = m.group(1)
    max_retries = 3
    base_timeout = 60000
    
    for attempt in range(max_retries):
        try:
            if attempt == 0:
                wait_until = "domcontentloaded"
                timeout = 30000
                extra_wait = 3000
            elif attempt == 1:
                wait_until = "load"
                timeout = 45000
                extra_wait = 5000
            else:
                wait_until = "networkidle"
                timeout = base_timeout
                extra_wait = 7000
            
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                page = await browser.new_page()
                
                response = await page.goto(url, wait_until=wait_until, timeout=timeout)
                
                # ÏÉÅÌíà ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄ ÏΩòÌÖêÏ∏† ÎåÄÍ∏∞
                try:
                    await page.wait_for_selector('.product-title, .prd-tit, .ui-view-info', timeout=10000)
                except Exception:
                    pass
                await page.wait_for_timeout(extra_wait)
                
                status_code = response.status if response else None
                if status_code and status_code >= 400:
                    logger.error(f"‚ùå HTTP {status_code}: {url}")
                
                try:
                    await page.wait_for_selector("#cfmClContents", timeout=10000)
                except:
                    logger.warning("‚ö†Ô∏è Main content load failed")
                
                title = await page.evaluate("""
                    () => {
                        const titleEl = document.querySelector('h1') || document.querySelector('.product-title') || document.querySelector('h2');
                        return titleEl ? titleEl.textContent.trim() : 'No title found';
                    }
                """)
                
                # ÏïÑÏΩîÎîîÏñ∏ Ìä∏Î¶¨Í±∞ ÌÉêÏßÄ Î∞è ÌÅ¥Î¶≠
                accordion_triggers = await page.evaluate("""
                    () => {
                        const triggers = [];
                        for (let i = 1; i <= 10; i++) {
                            const trigger = document.querySelector(`#title${i}`);
                            if (trigger) {
                                triggers.push({
                                    id: `title${i}`,
                                    text: trigger.textContent.trim(),
                                    visible: trigger.offsetParent !== null
                                });
                            }
                        }
                        return triggers;
                    }
                """)
                
                if accordion_triggers:
                    for trigger in accordion_triggers:
                        try:
                            await page.click(f"#{trigger['id']}", timeout=5000)
                            await page.wait_for_timeout(1000)
                        except:
                            continue
                
                # Ï∂îÏ≤ú Ïª®ÌÖêÏ∏† Ï∂îÏ∂ú
                recommendations = []
                try:
                    await page.wait_for_timeout(3000)
                    
                    raw_reco = await page.evaluate("""() => {
                        const abs = (u) => {
                            try { const a = document.createElement('a'); a.href = u; return a.href; } catch(e){ return u; }
                        };
                        const top = Array.from(document.querySelectorAll('ul.three-list li a')).map(a => ({
                            title: (a.textContent||'').trim(),
                            url: abs(a.getAttribute('href')||a.href||'')
                        })).filter(x => x.title && x.url);

                        const bundle = [];
                        ['#trigger1-1-1', '#trigger1-1-2'].forEach(sel => {
                            const root = document.querySelector(sel);
                            if (!root) return;
                            root.querySelectorAll('.bxslider li a').forEach(a => {
                                const title = ((a.querySelector('p')?.textContent) || a.textContent || '').trim();
                                const url = abs(a.getAttribute('href')||a.href||'');
                                const main = (a.querySelector('.recommend-main-info')?.textContent||'').trim();
                                const sub = (a.querySelector('.recommend-sub-info')?.textContent||'').trim();
                                const desc = [main, sub].filter(Boolean).join(' ');
                                if (title && url) bundle.push({ title, url, desc });
                            });
                        });

                        const planVariant = Array.from(document.querySelectorAll('.N-head-btn-area a'))
                            .filter(a => !a.classList.contains('icon'))
                            .map(a => ({
                                title: (a.textContent||'').trim(),
                                url: abs(a.getAttribute('href')||a.href||'')
                            }))
                            .filter(x => x.title && x.url && !x.url.startsWith('javascript:'));

                        const otherPlan = [];
                        const extraService = [];
                        Array.from(document.querySelectorAll('ul.N-compare-suggest-list li a')).forEach(a => {
                            const title = ((a.querySelector('strong.tit')?.textContent) || a.textContent || '').trim();
                            const url = abs(a.getAttribute('href')||a.href||'');
                            const onclick = (a.getAttribute('onclick')||'');
                            if (title && url) {
                                if (onclick.includes('Ï∂îÏ≤úÎ∂ÄÍ∞ÄÏÑúÎπÑÏä§')) extraService.push({ title, url });
                                else otherPlan.push({ title, url });
                            }
                        });

                        return { top, bundle, planVariant, otherPlan, extraService };
                    }""")
                    
                    def to_abs(u: str) -> str:
                        if not u:
                            return ''
                        if u.startswith('http'):
                            return u
                        if u.startswith('/'):
                            return f"https://product.kt.com{u}"
                        return u

                    recommendations_list = []
                    
                    for item in raw_reco.get('top', [])[:10]:
                        url_abs = to_abs(item.get('url', ''))
                        if url_abs:
                            recommendations_list.append({
                                'kind': 'top',
                                'name': item.get('title', ''),
                                'desc': '',
                                'url': url_abs,
                                'murl': _to_murl(url_abs)
                            })

                    seen = set()
                    for item in raw_reco.get('bundle', [])[:20]:
                        url_abs = to_abs(item.get('url', ''))
                        if not url_abs or url_abs in seen:
                            continue
                        seen.add(url_abs)
                        recommendations_list.append({
                            'kind': 'bundle_option',
                            'name': item.get('title', ''),
                            'desc': item.get('desc') or '',
                            'url': url_abs,
                            'murl': _to_murl(url_abs)
                        })

                    for item in raw_reco.get('planVariant', [])[:10]:
                        url_abs = to_abs(item.get('url', ''))
                        if url_abs and not url_abs.startswith('javascript:'):
                            recommendations_list.append({
                                'kind': 'plan_variant',
                                'name': item.get('title', ''),
                                'desc': '',
                                'url': url_abs,
                                'murl': _to_murl(url_abs)
                            })

                    for item in raw_reco.get('otherPlan', [])[:10]:
                        url_abs = to_abs(item.get('url', ''))
                        if url_abs:
                            recommendations_list.append({
                                'kind': 'other_plan',
                                'name': item.get('title', ''),
                                'desc': '',
                                'url': url_abs,
                                'murl': _to_murl(url_abs)
                            })

                    for item in raw_reco.get('extraService', [])[:10]:
                        url_abs = to_abs(item.get('url', ''))
                        if url_abs:
                            recommendations_list.append({
                                'kind': 'extra_service',
                                'name': item.get('title', ''),
                                'desc': '',
                                'url': url_abs,
                                'murl': _to_murl(url_abs)
                            })

                    recommendations = recommendations_list
                    
                except Exception as e:
                    logger.error(f"‚ùå Recommendations failed: {str(e)}")
                    recommendations = []

                # N-pdt-compare-column ÏûêÏÑ∏Ìûà Î≥¥Í∏∞ Ï∂îÏ∂ú
                additional_details = []
                try:
                    detail_links = await page.evaluate("""() => {
                        const abs = (u) => {
                            try { const a = document.createElement('a'); a.href = u; return a.href; } catch(e){ return u; }
                        };
                        
                        const results = [];
                        const columns = document.querySelectorAll('.N-pdt-compare-column');
                        
                        columns.forEach(col => {
                            const link = col.querySelector('a.btn-reduced');
                            if (!link) return;
                            
                            const linkText = (link.textContent || '').trim();
                            if (linkText !== 'ÏûêÏÑ∏Ìûà Î≥¥Í∏∞') return;
                            
                            const nameEl = col.querySelector('strong.name');
                            if (!nameEl) return;
                            
                            const name = (nameEl.textContent || '').trim();
                            const href = abs(link.getAttribute('href') || link.href || '');
                            
                            if (name && href && href.startsWith('http')) {
                                results.push({ name, href });
                            }
                        });
                        
                        return results;
                    }""")
                    
                    if detail_links:
                        for link_info in detail_links:
                            try:
                                clean_name = link_info['name']
                                clean_name = re.sub(r'[\r\n]+', ' ', clean_name)
                                clean_name = re.sub(r'\s+', ' ', clean_name)
                                clean_name = re.sub(r'[^\w\s„Ñ±-„Öé„Öè-„Ö£Í∞Ä-Ìû£/\-\(\)]', '', clean_name)
                                clean_name = clean_name.strip()
                                
                                detail_url = link_info['href']
                                sub_result = await handle_product_detail(detail_url, fclient=fclient, menu=menu)
                                
                                if sub_result:
                                    sub_result['parent_product_name'] = clean_name
                                    sub_result['parent_url'] = url
                                    additional_details.append(sub_result)
                            except:
                                continue
                except:
                    pass

                # ÏΩòÌÖêÏ∏† ÏàòÏßë
                combined_html = ""
                markdown_text = ""
                try:
                    combined_html = await page.evaluate("""
                        () => {
                            const mainContent = document.querySelector('#cfmClContents');
                            if (!mainContent) return '';
                            
                            const excludeSelectors = [
                                '#cfmClHeader', '#cfmClFooter', '#cfmClSkip', 
                                'form', '.header', '.footer', '.nav', ".swiper-controls-wrapper",
                                ".opage-hashtag-arrow", ".swiper-button-next", ".swiper-button-prev",
                                ".icon.kakao", ".icon.facebook", ".icon.twitter", ".icon.youtube",
                                ".location", ".sns-area", ".opener", "a[onclick*='KT_trackClicks']", 
                                '.together-recommend-area', ".N-compare-suggest-list", ".top-three-box", ".tabs",
                            ];
                            
                            const contentClone = mainContent.cloneNode(true);
                            
                            excludeSelectors.forEach(selector => {
                                const elements = contentClone.querySelectorAll(selector);
                                elements.forEach(el => el.remove());
                            });
                            
                            return contentClone.outerHTML;
                        }
                    """)
                    
                    if combined_html:
                        markdown_text = md(combined_html)
                    else:
                        combined_html = await page.eval_on_selector("body", "el => el.outerHTML")
                        markdown_text = md(combined_html)
                        
                except Exception as e:
                    logger.error(f"‚ùå Content failed: {str(e)}")
                    markdown_text = "ÏΩòÌÖêÏ∏† Ï≤òÎ¶¨ Ïã§Ìå®"

                await browser.close()
                
                logger.info(f"‚úÖ Product detail done: '{title}'")
                
                return {
                    "url": url,
                    "murl": _to_murl(url),
                    "title": title,
                    "markdown": markdown_text,
                    "html": combined_html or "",
                    "item_code": item_code,
                    "accordion_count": len(accordion_triggers),
                    "content_length": len(combined_html) if combined_html else 0,
                    "recommendations": recommendations or [],
                    "additional_details": additional_details or [],
                    "special_processed": True,
                    "playwright_processed": True
                }
                
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"‚ö†Ô∏è Attempt {attempt + 1} failed: {str(e)}")
                await asyncio.sleep(5)
                continue
            else:
                logger.error(f"‚ùå Product detail failed: {str(e)}")
                return None


async def handle_wdic_mobile_list(
    url: str, 
    fclient: Any, 
    menu: Optional[str] = None
) -> Dict[str, Any]:
    """
    KT ÏÉÅÌíàÏÇ¨Ï†Ñ(wDic) Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù Ìï∏Îì§Îü¨
    """
    logger.info(f"üîó wDic list: {url}")
    
    base_host = 'https://product.kt.com'
    menus, datas = [], []

    async def _capture_list_snapshot(page, base_menu: str = "", tab_text: str = "", sub_filter_text: str = ""):
        try:
            html = await page.evaluate("""
                () => {
                    const root = document.querySelector('#cfmClContents') || document.body;
                    if (!root) return '';
                    const clone = root.cloneNode(true);
                    const removeSelectors = [
                        '#cfmClHeader', '#cfmClFooter', '#cfmClSkip',
                        '.location', '.sns-area', '.find-center'
                    ];
                    removeSelectors.forEach(sel => {
                        clone.querySelectorAll(sel).forEach(el => el.remove());
                    });
                    return clone.outerHTML;
                }
            """)
            markdown_text = md(html) if html else ""
            final_menu = (base_menu or "").strip()
            if tab_text:
                final_menu = f"{final_menu}^{tab_text}" if final_menu else tab_text
            if sub_filter_text:
                final_menu = f"{final_menu}^{sub_filter_text}" if final_menu else sub_filter_text
            menus.append({'menu': final_menu, 'url': page.url, 'murl': _to_murl(page.url)})
            datas.append({
                "url": page.url,
                "murl": _to_murl(page.url),
                "title": final_menu,
                "markdown": markdown_text,
                "html": html or "",
                "special_processed": True,
                "playwright_processed": True,
                "is_list_snapshot": True
            })
        except Exception as e:
            logger.debug(f"üîç Snapshot failed: {str(e)}")

    async def _click_more_until_exhausted(page) -> int:
        clicks = 0
        guard = 0
        while guard < 50:
            guard += 1
            try:
                before = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                
                clicked = await page.evaluate(r"""
                    () => {
                        const btn = document.querySelector('.btn-more');
                        if (!btn) return false;
                        const style = btn.getAttribute('style') || '';
                        const css = getComputedStyle(btn);
                        const visible = btn.offsetParent !== null && css.display !== 'none' && css.visibility !== 'hidden' && !/display:\s*none/i.test(style);
                        if (!visible) return false;
                        btn.click();
                        return true;
                    }
                """)
                
                if not clicked:
                    break
                
                clicks += 1
                await page.wait_for_timeout(1200)

                after = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")

                if after <= before:
                    await page.wait_for_timeout(1500)
                    after = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")

                if after <= before:
                    btn_check = await page.evaluate(r"""
                        () => {
                            const b = document.querySelector('.btn-more');
                            if (!b) return false;
                            const s = b.getAttribute('style')||'';
                            const c = getComputedStyle(b);
                            return b.offsetParent !== null && c.display !== 'none' && c.visibility !== 'hidden' && !/display:\s*none/i.test(s);
                        }
                    """)
                    if not btn_check:
                        break
            except:
                break
        return clicks

    async def _ensure_filter_all(page):
        try:
            changed = await page.evaluate(r"""
                () => {
                    function isVisible(el){
                        if(!el) return false;
                        const style = getComputedStyle(el);
                        return el.offsetParent !== null && style.display !== 'none' && style.visibility !== 'hidden';
                    }
                    const cands = Array.from(document.querySelectorAll('a, button, label'));
                    for(const el of cands){
                        const txt = (el.textContent||'').replace(/\s+/g,'').trim();
                        if (txt.includes('Ï†ÑÏ≤¥') && isVisible(el)) {
                            try { el.click(); return true; } catch(e) { return false; }
                        }
                    }
                    return false;
                }
            """)
            if changed:
                await page.wait_for_timeout(600)
        except:
            pass

    async def _extract_items(page) -> list:
        items = await page.evaluate("""
            () => {
                const results = [];
                const anchors = Array.from(document.querySelectorAll('.plan-list-area .btns a[href*="productDetail"]'));

                function normRel(href){
                    try{
                        const a = document.createElement('a');
                        a.href = href;
                        const rel = `${a.pathname}${a.search||''}`;
                        return rel.startsWith('/wDic/') ? rel : (rel.startsWith('/') ? rel : `/wDic/${rel}`);
                    }catch(e){
                        return href.startsWith('/wDic/') ? href : (href.startsWith('/') ? href : `/wDic/${href}`);
                    }
                }

                function getNearestTitle(anchor){
                    const titleSelector = '.title, .plan_tit, .tit, .name, strong, span.two-line';
                    
                    function extractTextWithoutSpan(element) {
                        if (!element) return '';
                        if (element.classList && element.classList.contains('title')) {
                            let text = '';
                            for (const child of element.childNodes) {
                                if (child.nodeType === Node.TEXT_NODE) {
                                    text += child.textContent;
                                } else if (child.nodeType === Node.ELEMENT_NODE && child.tagName !== 'SPAN') {
                                    text += child.textContent;
                                }
                            }
                            return text.trim();
                        }
                        return (element.textContent || '').trim();
                    }
                    
                    let el = anchor.closest('li, tr, .plan-list li, .prd-list li');
                    if (el){
                        const t = el.querySelector(titleSelector);
                        if (t) return extractTextWithoutSpan(t);
                    }
                    let cur = anchor.parentElement;
                    for (let depth=0; depth<5 && cur; depth++){
                        let prev = cur.previousElementSibling;
                        let hops = 0;
                        while(prev && hops < 10){
                            const t = prev.querySelector(titleSelector);
                            if (t) return extractTextWithoutSpan(t);
                            prev = prev.previousElementSibling;
                            hops++;
                        }
                        cur = cur.parentElement;
                    }
                    let parent = anchor.parentElement;
                    for (let i=0; i<6 && parent; i++){
                        const t = parent.querySelector(titleSelector);
                        if (t) return extractTextWithoutSpan(t);
                        parent = parent.parentElement;
                    }
                    const at = (anchor.textContent||'').trim();
                    if (!/ÏÉÅÏÑ∏|ÏûêÏÑ∏Ìûà/.test(at)) return at;
                    return '';
                }

                anchors.forEach(a => {
                    const href = a.getAttribute('href') || a.href || '';
                    if (!href || href === '#' || href.startsWith('javascript:')) return;
                    const rel = normRel(href);
                    const title = getNearestTitle(a);
                    results.push({ title: title || '', relHref: rel });
                });

                return results;
            }
        """)
        return items or []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        response = await page.goto(url, wait_until='domcontentloaded', timeout=60000)
        
        # ÏÉÅÌíà Î™©Î°ù ÎåÄÍ∏∞
        try:
            await page.wait_for_selector('.plan-list-area .plan-list li, ul.N-compare-suggest-list li', timeout=15000)
            logger.info("‚úÖ Product list loaded")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Product list not loaded: {e}")
        await page.wait_for_timeout(1200)

        status_code = response.status if response else None
        if status_code and status_code >= 400:
            logger.error(f"‚ùå HTTP {status_code}: {url}")

        try:
            await page.wait_for_selector('ul.ui-tab-list, ul.red-select', timeout=10000)
        except:
            pass

        tabs = await page.evaluate("""
            () => {
                const arr = [];
                const ulSelectors = ['ul.ui-tab-list', 'ul.red-select'];
                let ul = null;
                
                for (const sel of ulSelectors) {
                    ul = document.querySelector(sel);
                    if (ul) break;
                }
                
                if (!ul) {
                    arr.push({ liId: null, text: 'Ï†ÑÏ≤¥' });
                    return arr;
                }
                
                const liElements = Array.from(ul.querySelectorAll('li'));
                liElements.forEach((li) => {
                    const a = li.querySelector('a');
                    if (!a) return;
                    
                    const text = (a.textContent || '').trim();
                    if (text === 'Ï∂îÏ≤ú') return;
                    
                    const liId = li.getAttribute('id') || li.id || null;
                    arr.push({ liId, text });
                });
                
                return arr;
            }
        """)
        if not tabs:
            tabs = [{'liId': None, 'text': 'Ï†ÑÏ≤¥'}]

        detail_targets = []

        try:
            await _capture_list_snapshot(page, base_menu=(menu or "").strip())
        except:
            pass

        for tab in tabs:
            try:
                li_id = tab.get('liId')
                if li_id is not None:
                    # ÌÅ¥Î¶≠ Ï†Ñ Î¶¨Ïä§Ìä∏ Í∞úÏàò Í∏∞Î°ù
                    prev_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                    
                    tab_clicked = await page.evaluate(f"""
                        () => {{
                            const ulSelectors = ['ul.ui-tab-list', 'ul.red-select'];
                            let ul = null;
                            
                            for (const sel of ulSelectors) {{
                                ul = document.querySelector(sel);
                                if (ul) break;
                            }}
                            
                            if (!ul) return false;
                            
                            const li = ul.querySelector('li[id="{li_id}"]') || ul.querySelector('li#{li_id}');
                            if (!li) return false;
                            
                            const a = li.querySelector('a');
                            if (!a) return false;
                            
                            a.click();
                            return true;
                        }}
                    """)
                    if tab_clicked:
                        # ÎÑ§Ìä∏ÏõåÌÅ¨Í∞Ä ÏïàÏ†ïÎê† ÎïåÍπåÏßÄ ÎåÄÍ∏∞
                        try:
                            await page.wait_for_load_state('networkidle', timeout=5000)
                        except Exception:
                            pass
                        
                        # Ï∂îÍ∞ÄÎ°ú Î¶¨Ïä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏ ÌôïÏù∏ (ÏµúÎåÄ 3Ï¥à)
                        for _ in range(6):
                            await page.wait_for_timeout(500)
                            new_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                            if new_count > 0:
                                break

                await _ensure_filter_all(page)
                await page.wait_for_timeout(800)

                sub_filters = await page.evaluate("""
                    () => {
                        const root = document.querySelector('.type-sub-item');
                        if (!root) return [];
                        const filters = Array.from(root.querySelectorAll('a, button, label'));
                        const result = [];
                        filters.forEach((el, idx) => {
                            const text = (el.textContent||'').trim();
                            if (text) result.push({ index: idx, text });
                        });
                        return result;
                    }
                """)

                if sub_filters:
                    # ÏÑúÎ∏å ÌïÑÌÑ∞Í∞Ä 2Í∞ú Ïù¥ÏÉÅÏù¥Í≥† "Ï†ÑÏ≤¥"Í∞Ä ÏûàÏúºÎ©¥ "Ï†ÑÏ≤¥"Î•º Ï†úÏô∏
                    # (Ï†ÑÏ≤¥ = Î™®Îì† Í∞úÎ≥Ñ ÌïÑÌÑ∞Ïùò Ìï©Ïù¥ÎØÄÎ°ú Ï§ëÎ≥µ Î∞©ÏßÄ)
                    has_all_filter = any(f.get('text', '').strip() == 'Ï†ÑÏ≤¥' for f in sub_filters)
                    if len(sub_filters) > 1 and has_all_filter:
                        sub_filters = [f for f in sub_filters if f.get('text', '').strip() != 'Ï†ÑÏ≤¥']
                        logger.info(f"ÌÉ≠ '{tab.get('text','')}': ÏÑúÎ∏å ÌïÑÌÑ∞ 'Ï†ÑÏ≤¥' Ï†úÏô∏, {len(sub_filters)}Í∞ú Í∞úÎ≥Ñ ÌïÑÌÑ∞Îßå ÏàúÌöå")
                    else:
                        logger.info(f"ÌÉ≠ '{tab.get('text','')}': ÏÑúÎ∏å ÌïÑÌÑ∞ {len(sub_filters)}Í∞ú Î∞úÍ≤¨, Î™®Îëê ÏàúÌöå")
                    
                    for sub_filter in sub_filters:
                        
                        try:
                            # ÏÑúÎ∏å ÌïÑÌÑ∞ ÌÅ¥Î¶≠ Ï†Ñ ÌòÑÏû¨ Î¶¨Ïä§Ìä∏ Í∞úÏàò Í∏∞Î°ù
                            prev_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                            
                            # ÏÑúÎ∏å ÌïÑÌÑ∞ ÌÅ¥Î¶≠
                            sub_clicked = await page.evaluate(f"""
                                () => {{
                                    const root = document.querySelector('.type-sub-item');
                                    if (!root) return false;
                                    const filters = Array.from(root.querySelectorAll('a, button, label'));
                                    if (filters.length > {sub_filter['index']}) {{
                                        filters[{sub_filter['index']}].click();
                                        return true;
                                    }}
                                    return false;
                                }}
                            """)
                            if sub_clicked:
                                # ÎÑ§Ìä∏ÏõåÌÅ¨Í∞Ä ÏïàÏ†ïÎê† ÎïåÍπåÏßÄ ÎåÄÍ∏∞ (ÏµúÎåÄ 5Ï¥à)
                                try:
                                    await page.wait_for_load_state('networkidle', timeout=5000)
                                except Exception:
                                    pass
                                
                                # Ï∂îÍ∞ÄÎ°ú Î¶¨Ïä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏ ÌôïÏù∏ (ÏµúÎåÄ 3Ï¥à)
                                for _ in range(6):
                                    await page.wait_for_timeout(500)
                                    new_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                                    if new_count > 0 and new_count != prev_count:
                                        break

                            clicks = await _click_more_until_exhausted(page)
                            items = await _extract_items(page)
                            
                            # ÌòÑÏû¨ ÌÉ≠+ÏÑúÎ∏åÌïÑÌÑ∞Ïùò Î™©Î°ù ÌôîÎ©¥ÎèÑ Ï∫°Ï≤ò
                            try:
                                await _capture_list_snapshot(
                                    page,
                                    base_menu=(menu or "").strip(),
                                    tab_text=tab.get('text', '').strip(),
                                    sub_filter_text=sub_filter.get('text', '').strip()
                                )
                            except Exception:
                                pass

                            li_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                            
                            # ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞úÏùº Îïå Î∞©Ïñ¥ Î°úÏßÅ: Ïû¨ÏãúÎèÑ
                            if len(items) == 0:
                                if clicks == 0 and li_count == 0:
                                    # ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠Ïù¥ 0ÌöåÏù¥Í≥† Î¶¨Ïä§Ìä∏ÎèÑ ÏóÜÎäî Í≤ΩÏö∞: ÌéòÏù¥ÏßÄ ÏÉàÎ°úÍ≥†Ïπ® ÌõÑ Ïû¨ÏãúÎèÑ
                                    logger.warning(f"‚ö†Ô∏è  ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠ 0Ìöå, ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú (li={li_count}) - ÌéòÏù¥ÏßÄ ÏÉàÎ°úÍ≥†Ïπ® ÌõÑ Ïû¨ÏãúÎèÑ Ï§ë...")
                                    await page.reload(timeout=10000)
                                    await page.wait_for_timeout(2000)
                                    try:
                                        await page.wait_for_load_state('networkidle', timeout=5000)
                                    except Exception:
                                        pass
                                    # ÏÑúÎ∏å ÌïÑÌÑ∞ Îã§Ïãú ÌÅ¥Î¶≠
                                    if sub_clicked:
                                        sub_clicked = await page.evaluate(f"""
                                            () => {{
                                                const root = document.querySelector('.type-sub-item');
                                                if (!root) return false;
                                                const filters = Array.from(root.querySelectorAll('a, button, label'));
                                                if (filters.length > {sub_filter['index']}) {{
                                                    filters[{sub_filter['index']}].click();
                                                    return true;
                                                }}
                                                return false;
                                            }}
                                        """)
                                        if sub_clicked:
                                            await page.wait_for_timeout(2000)
                                    clicks = await _click_more_until_exhausted(page)
                                    items = await _extract_items(page)
                                    li_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                                elif li_count > 0:
                                    # Î¶¨Ïä§Ìä∏Îäî ÏûàÏßÄÎßå ÏÉÅÏÑ∏ÎßÅÌÅ¨Í∞Ä ÏóÜÎäî Í≤ΩÏö∞: ÌéòÏù¥ÏßÄ Î°úÎìú ÎåÄÍ∏∞ ÌõÑ Ïû¨ÏãúÎèÑ
                                    logger.warning(f"‚ö†Ô∏è  ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú Í∞êÏßÄ (li={li_count}), ÌéòÏù¥ÏßÄ Î°úÎìú Ïû¨ÏãúÎèÑ Ï§ë...")
                                    await page.wait_for_timeout(2000)
                                    try:
                                        await page.wait_for_load_state('networkidle', timeout=5000)
                                    except Exception:
                                        pass
                                    items = await _extract_items(page)
                                
                                if len(items) == 0:
                                    logger.error(f"‚ùå Ïû¨ÏãúÎèÑ ÌõÑÏóêÎèÑ ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú: ÌÉ≠='{tab.get('text','')}', ÏÑúÎ∏åÌïÑÌÑ∞='{sub_filter.get('text','')}', clicks={clicks}, li={li_count}")
                            
                            logger.info(f"ÌÉ≠ '{tab.get('text','')}' > ÏÑúÎ∏åÌïÑÌÑ∞ '{sub_filter.get('text','')}' ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠ {clicks}Ìöå, li={li_count}, ÏÉÅÏÑ∏ÎßÅÌÅ¨={len(items)}Í∞ú ÏàòÏßë")

                            for it in items:
                                if not it.get('relHref'):
                                    continue
                                detail_targets.append({
                                    'tab': tab.get('text', ''),
                                    'sub_filter': sub_filter.get('text', ''),
                                    'title': it.get('title', '').strip() or '(Ï†úÎ™© ÏóÜÏùå)',
                                    'relHref': it['relHref']
                                })
                        except Exception as e:
                            logger.warning(f"ÏÑúÎ∏å ÌïÑÌÑ∞ '{sub_filter.get('text','')}' Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}")
                            continue
                else:
                    # ÏÑúÎ∏å ÌïÑÌÑ∞ ÏóÜÏúºÎ©¥ Í∏∞Ï°¥ Î°úÏßÅ
                    clicks = await _click_more_until_exhausted(page)
                    items = await _extract_items(page)
                    
                    # ÌòÑÏû¨ ÌÉ≠Ïùò Î™©Î°ù ÌôîÎ©¥ÎèÑ Ï∫°Ï≤ò
                    try:
                        await _capture_list_snapshot(
                            page,
                            base_menu=(menu or "").strip(),
                            tab_text=tab.get('text', '').strip()
                        )
                    except Exception:
                        pass

                    li_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                    
                    # ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞úÏùº Îïå Î∞©Ïñ¥ Î°úÏßÅ: Ïû¨ÏãúÎèÑ
                    if len(items) == 0:
                        if clicks == 0 and li_count == 0:
                            # ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠Ïù¥ 0ÌöåÏù¥Í≥† Î¶¨Ïä§Ìä∏ÎèÑ ÏóÜÎäî Í≤ΩÏö∞: ÌéòÏù¥ÏßÄ ÏÉàÎ°úÍ≥†Ïπ® ÌõÑ Ïû¨ÏãúÎèÑ
                            logger.warning(f"‚ö†Ô∏è  ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠ 0Ìöå, ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú (li={li_count}) - ÌéòÏù¥ÏßÄ ÏÉàÎ°úÍ≥†Ïπ® ÌõÑ Ïû¨ÏãúÎèÑ Ï§ë...")
                            await page.reload(timeout=10000)
                            await page.wait_for_timeout(2000)
                            try:
                                await page.wait_for_load_state('networkidle', timeout=5000)
                            except Exception:
                                pass
                            clicks = await _click_more_until_exhausted(page)
                            items = await _extract_items(page)
                            li_count = await page.evaluate("document.querySelectorAll('.plan-list-area .plan-list li').length")
                        elif li_count > 0:
                            # Î¶¨Ïä§Ìä∏Îäî ÏûàÏßÄÎßå ÏÉÅÏÑ∏ÎßÅÌÅ¨Í∞Ä ÏóÜÎäî Í≤ΩÏö∞: ÌéòÏù¥ÏßÄ Î°úÎìú ÎåÄÍ∏∞ ÌõÑ Ïû¨ÏãúÎèÑ
                            logger.warning(f"‚ö†Ô∏è  ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú Í∞êÏßÄ (li={li_count}), ÌéòÏù¥ÏßÄ Î°úÎìú Ïû¨ÏãúÎèÑ Ï§ë...")
                            await page.wait_for_timeout(2000)
                            try:
                                await page.wait_for_load_state('networkidle', timeout=5000)
                            except Exception:
                                pass
                            items = await _extract_items(page)
                        
                        if len(items) == 0:
                            logger.error(f"‚ùå Ïû¨ÏãúÎèÑ ÌõÑÏóêÎèÑ ÏÉÅÏÑ∏ÎßÅÌÅ¨ 0Í∞ú: ÌÉ≠='{tab.get('text','')}', clicks={clicks}, li={li_count}")
                    
                    logger.info(f"ÌÉ≠ '{tab.get('text','')}' ÎçîÎ≥¥Í∏∞ ÌÅ¥Î¶≠ {clicks}Ìöå, li={li_count}, ÏÉÅÏÑ∏ÎßÅÌÅ¨={len(items)}Í∞ú ÏàòÏßë")

                    for it in items:
                        if not it.get('relHref'):
                            continue
                        detail_targets.append({
                            'tab': tab.get('text', ''),
                            'title': it.get('title', '').strip() or '(Ï†úÎ™© ÏóÜÏùå)',
                            'relHref': it['relHref']
                        })
            except Exception as e:
                logger.warning(f"ÌÉ≠ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}")
                continue

        # Ï§ëÎ≥µ Ï†úÍ±∞ (ItemCode Í∏∞Ï§Ä)
        seen_itemcodes = {}  # itemcode -> Ï≤´ Î≤àÏß∏ Î∞úÍ≤¨Îêú target Ï†ïÎ≥¥
        unique_targets = []
        duplicate_items = []  # Ï§ëÎ≥µ Ï†úÍ±∞Îêú ÏïÑÏù¥ÌÖú Î™©Î°ù
        
        for target in detail_targets:
            match = re.search(r'ItemCode=(\d+)', target['relHref'])
            if match:
                itemcode = match.group(1)
                if itemcode in seen_itemcodes:
                    first_target = seen_itemcodes[itemcode]
                    duplicate_items.append({
                        'itemcode': itemcode,
                        'first_tab': first_target['tab'],
                        'first_sub': first_target.get('sub_filter', ''),
                        'duplicate_tab': target['tab'],
                        'duplicate_sub': target.get('sub_filter', ''),
                        'title': target.get('title', '')
                    })
                    continue
                seen_itemcodes[itemcode] = target
            unique_targets.append(target)
        
        # ÌÉ≠Î≥Ñ Í∞úÏàò Ïπ¥Ïö¥Ìä∏ (Ï§ëÎ≥µ Ï†úÍ±∞ Ï†ÑÍ≥º ÌõÑ)
        tab_counts_before = {}
        for target in detail_targets:
            tab = target.get('tab', 'Í∏∞ÌÉÄ')
            tab_counts_before[tab] = tab_counts_before.get(tab, 0) + 1
        
        tab_counts_after = {}
        for target in unique_targets:
            tab = target.get('tab', 'Í∏∞ÌÉÄ')
            tab_counts_after[tab] = tab_counts_after.get(tab, 0) + 1
        
        logger.info(f"Ï§ëÎ≥µ Ï†úÍ±∞: Ï†ÑÏ≤¥ {len(detail_targets)}Í∞ú ‚Üí Ïú†ÎãàÌÅ¨ {len(unique_targets)}Í∞ú (Ï§ëÎ≥µ {len(duplicate_items)}Í∞ú Ï†úÍ±∞)")
        
        # Ï§ëÎ≥µ Ï†úÍ±∞Îêú ÏïÑÏù¥ÌÖú ÏÉÅÏÑ∏ Î°úÍπÖ
        if duplicate_items:
            logger.info(f"\n{'='*80}")
            logger.info(f"üîç Ï§ëÎ≥µ Ï†úÍ±∞Îêú ÏïÑÏù¥ÌÖú Î™©Î°ù ({len(duplicate_items)}Í∞ú):")
            logger.info(f"{'='*80}")
            for i, dup in enumerate(duplicate_items, 1):
                first_location = f"{dup['first_tab']}"
                if dup['first_sub']:
                    first_location += f" > {dup['first_sub']}"
                
                dup_location = f"{dup['duplicate_tab']}"
                if dup['duplicate_sub']:
                    dup_location += f" > {dup['duplicate_sub']}"
                
                logger.info(f"   {i}. ItemCode={dup['itemcode']}")
                logger.info(f"      Ïú†ÏßÄ: [{first_location}]")
                logger.info(f"      ÏÇ≠Ï†ú: [{dup_location}]")
                logger.info(f"      Ï†úÎ™©: {dup['title'][:50]}")
            logger.info(f"{'='*80}\n")
        
        if tab_counts_after:
            # ÌÉ≠Î≥Ñ Ï§ëÎ≥µ Ï†úÍ±∞ Ï†ÑÌõÑ ÎπÑÍµê
            logger.info("üìä ÌÉ≠Î≥Ñ Í∞úÏàò (Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ ‚Üí ÌõÑ):")
            for tab in sorted(set(list(tab_counts_before.keys()) + list(tab_counts_after.keys()))):
                before = tab_counts_before.get(tab, 0)
                after = tab_counts_after.get(tab, 0)
                diff = before - after
                if diff > 0:
                    logger.info(f"   {tab}: {before} ‚Üí {after} (Ï§ëÎ≥µ {diff}Í∞ú)")
                else:
                    logger.info(f"   {tab}: {after}")
        
        detail_targets = unique_targets

        # ÏÉÅÏÑ∏ Ï≤òÎ¶¨
        for i, target in enumerate(detail_targets, 1):
            detail_url = urljoin(base_host, target['relHref'])
            try:
                result = await handle_product_detail(detail_url, fclient, menu)
                if not result:
                    continue

                base_menu_str = (menu or '').strip()
                tab_prefix = target.get('tab', '').strip()
                sub_filter_name = target.get('sub_filter', '').strip()
                title_suffix = target.get('title', '').strip()
                final_menu = base_menu_str
                if tab_prefix:
                    final_menu = f"{final_menu}^{tab_prefix}" if final_menu else tab_prefix
                if sub_filter_name:
                    final_menu = f"{final_menu}^{sub_filter_name}" if final_menu else sub_filter_name
                if title_suffix:
                    final_menu = f"{final_menu}^{title_suffix}" if final_menu else title_suffix

                menus.append({'menu': final_menu or (result.get('title') or ''), 'url': detail_url})
                datas.append(result)
                logger.info(f"[{i}/{len(detail_targets)}] ÏÉÅÏÑ∏ Ï≤òÎ¶¨ ÏôÑÎ£å: {detail_url}")
            except Exception as e:
                logger.error(f"ÏÉÅÏÑ∏ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {detail_url} - {str(e)}")
                continue

        await browser.close()

    logger.info(f"‚úÖ wDic Î™©Î°ù Ï≤òÎ¶¨ ÏôÑÎ£å: {len(datas)}Í∞ú ÏïÑÏù¥ÌÖú ÏàòÏßë")

    return {
        'menus': menus,
        'datas': datas,
        'metadata': {
            'url': url,
            'total_items': len(datas),
            'source': 'wdic_list',
            'special_processed': True,
            'playwright_processed': True
        }
    }


# Ìï∏Îì§Îü¨ Îì±Î°ù
register_page_handler(
    r'https?://product\.kt\.com/wDic/(soho/)?productDetail\.do\?ItemCode=.*',
    handle_product_detail
)

register_page_handler(
    r'https?://product\.kt\.com/wDic/.*index\.do\?CateCode=\d+',
    handle_wdic_mobile_list
)




