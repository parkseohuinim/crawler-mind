"""
ë„¤íŠ¸ì›Œí¬ ê³µì§€ì‚¬í•­ ê´€ë ¨ í•¸ë“¤ëŸ¬

ë„¤íŠ¸ì›Œí¬ ê³µì§€ì‚¬í•­ ëª©ë¡ ë° ìƒì„¸ í˜ì´ì§€ ì²˜ë¦¬
"""

import asyncio
import logging
import re
from datetime import datetime, timedelta
from typing import Any, Dict, Optional

from playwright.async_api import async_playwright
from markdownify import markdownify as md

from ..handler_registry import register_page_handler
from ..utils import sanitize_filename, format_content, create_markdown

logger = logging.getLogger(__name__)


async def handle_network_notice_detail(
    url: str, 
    fclient: Any, 
    cutoff_date: Optional[datetime] = None
) -> Dict[str, Any]:
    """
    ë„¤íŠ¸ì›Œí¬ ê³µì§€ì‚¬í•­ ê°œë³„ ê²Œì‹œë¬¼ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
    """
    logger.info(f"ğŸ”— Network notice detail: {url}")
    
    if cutoff_date is None:
        cutoff_date = datetime.now() - timedelta(days=365)
    
    metadata = None
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
            )
            page = await context.new_page()
            
            response = await page.goto(url, wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(5000)
            
            status_code = response.status if response else None
            if status_code and status_code >= 400:
                logger.error(f"âŒ HTTP {status_code}: {url}")
            
            try:
                await page.wait_for_load_state('domcontentloaded', timeout=30000)
                await page.wait_for_load_state('networkidle', timeout=30000)
            except Exception as e:
                logger.warning(f"âš ï¸ Load timeout: {str(e)}")
            
            title = await page.evaluate("""() => {
                const t = document.querySelector('h1.title');
                return t ? t.textContent.trim() : '';
            }""")
            raw_date = await page.evaluate("""() => {
                const d = document.querySelector('.desc');
                return d ? d.textContent.trim() : '';
            }""")
            
            if title and raw_date:
                content_html = ""
                for selector in ['.txt-content', '.contents', '.content', '.detail-content', '.notice-content', 'main', '.main-content']:
                    content_div = await page.query_selector(selector)
                    if content_div:
                        html = await content_div.inner_html()
                        if html.strip():
                            content_html = html
                            break
                
                next_link = await page.evaluate("""() => {
                    let nextLink = '';
                    const nextElement = document.querySelector('a[data-bno].next-area');
                    if (nextElement) {
                        const nextBno = nextElement.getAttribute('data-bno');
                        if (nextBno) {
                            const currentUrl = window.location.href;
                            const baseUrl = currentUrl.split('?')[0];
                            nextLink = `${baseUrl}?bno=${nextBno}`;
                        }
                    }
                    if (!nextLink) {
                        const allElements = document.querySelectorAll('*');
                        for (let elem of allElements) {
                            if (elem.textContent && elem.textContent.includes('ë‹¤ìŒê¸€')) {
                                const parent = elem.closest('a[data-bno]');
                                if (parent) {
                                    const nextBno = parent.getAttribute('data-bno');
                                    if (nextBno) {
                                        const currentUrl = window.location.href;
                                        const baseUrl = currentUrl.split('?')[0];
                                        nextLink = `${baseUrl}?bno=${nextBno}`;
                                        break;
                                    }
                                }
                            }
                        }
                    }
                    if (!nextLink) {
                        const nextLinks = document.querySelectorAll('a[href*="bno="]');
                        for (let link of nextLinks) {
                            if (link.textContent.includes('ë‹¤ìŒê¸€') || link.textContent.includes('ë‹¤ìŒ')) {
                                nextLink = link.href;
                                break;
                            }
                        }
                    }
                    return nextLink;
                }""")
                
                await browser.close()
                metadata = {
                    'title': title,
                    'rawDate': raw_date,
                    'nextLink': next_link,
                    'contentHtml': content_html
                }
            else:
                await browser.close()
                return {"error": "ì œëª© ë˜ëŠ” ë‚ ì§œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    except Exception as e:
        logger.error(f"âŒ Network notice failed: {str(e)}")
        return {"error": f"í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {str(e)}"}
    
    # ì»¨í…ì¸  HTMLì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
    if metadata['contentHtml']:
        content = md(metadata['contentHtml'])
    else:
        logger.info("âš ï¸ No HTML, trying fallback")
        try:
            result = await fclient.scrape_single_url(url)
            if result.get("markdown"):
                content = result["markdown"]
            else:
                content = "ì»¨í…ì¸  ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨"
        except Exception as e:
            content = "ì»¨í…ì¸  ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨"
            logger.error(f"âŒ Fallback failed: {str(e)}")
    
    # ì¹´í…Œê³ ë¦¬ì™€ ë‚ ì§œ ë¶„ë¦¬
    raw_date = metadata.get('rawDate', '')
    date_only_match = re.search(r'(\d{4}[.\-]\d{2}[.\-]\d{2})', raw_date)
    if date_only_match:
        actual_date = date_only_match.group(1)
        category = raw_date[:raw_date.find(actual_date)].strip() if raw_date.find(actual_date) > 0 else ""
    else:
        return {"error": f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {raw_date}"}
    
    # ë‚ ì§œ cutoff ì²´í¬
    date_match = re.search(r'(\d{4})\.(\d{1,2})\.(\d{1,2})', actual_date)
    if date_match:
        year, month, day = map(int, date_match.groups())
        post_date = datetime(year, month, day)
        if post_date < cutoff_date:
            return {"date_cutoff_reached": True, "date": actual_date}
    
    formatted_content = format_content(content)
    date_display = f"{actual_date}" + (f" (ì¹´í…Œê³ ë¦¬: {category})" if category else "")
    markdown_content = create_markdown(metadata['title'], date_display, formatted_content)
    
    next_url = None
    if metadata['nextLink'] and 'bno=' in metadata['nextLink']:
        next_url = metadata['nextLink']
    
    mobile_url = url.replace('inside.kt.com', 'm.kt.com') if 'inside.kt.com' in url else None
    
    startdate_hyphen = "0000-00-00"
    enddate_hyphen = "9999-99-99"
    try:
        dm = re.search(r"(\d{4})[.\-](\d{2})[.\-](\d{2})", actual_date)
        if dm:
            startdate_hyphen = f"{dm.group(1)}-{dm.group(2)}-{dm.group(3)}"
    except Exception:
        pass

    logger.info(f"âœ… Network notice done: '{metadata['title']}'")

    return {
        "url": url,
        "mobile_url": mobile_url,
        "murl": mobile_url or '',
        "title": metadata['title'],
        "category": category,
        "date": actual_date,
        "raw_date": metadata['rawDate'],
        "startdate": startdate_hyphen,
        "enddate": enddate_hyphen,
        "markdown": markdown_content,
        "html": metadata['contentHtml'] or content,
        "next_url": next_url,
        "special_processed": True,
        "playwright_processed": True
    }


async def handle_network_notice_main(
    url: str, 
    fclient: Any, 
    menu: Optional[str] = None
) -> Dict[str, Any]:
    """
    ë„¤íŠ¸ì›Œí¬ ê³µì§€ì‚¬í•­ ë©”ì¸ ëª©ë¡ í˜ì´ì§€ ì²˜ë¦¬
    """
    logger.info(f"ğŸ”— Network notice main: {url}")
    cutoff_date = datetime.now() - timedelta(days=365)
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
        )
        page = await context.new_page()
        response = await page.goto(url, wait_until='domcontentloaded', timeout=60000)
        first_bno = None
        
        status_code = response.status if response else None
        if status_code and status_code >= 400:
            logger.error(f"âŒ HTTP {status_code}: {url}")
        
        for attempt in range(3):
            try:
                await page.wait_for_selector('a[data-bno]', timeout=10000)
            except Exception:
                pass
            await page.wait_for_timeout(2000)
            first_bno = await page.evaluate("""() => {
                const firstLink = document.querySelector('a[data-bno]');
                return firstLink ? firstLink.getAttribute('data-bno') : null;
            }""")
            if first_bno:
                break
        await browser.close()
    
    if not first_bno:
        return {"error": "ì²« ë²ˆì§¸ ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    
    first_url = f"https://inside.kt.com/html/notice/net_notice_detail.html?bno={first_bno}"
    current_url = first_url
    total_processed = 0
    menus, datas = [], []
    max_iterations = 1000
    
    consecutive_errors = 0
    max_consecutive_errors = 3
    
    for i in range(max_iterations):
        if not current_url:
            break
        try:
            logger.info(f"ğŸ” Processing {total_processed + 1}: {current_url}")
            
            # ê°œë³„ ìƒì„¸ í˜ì´ì§€ì— 120ì´ˆ(2ë¶„) íƒ€ì„ì•„ì›ƒ ì ìš©
            try:
                result = await asyncio.wait_for(
                    handle_network_notice_detail(current_url, fclient, cutoff_date),
                    timeout=120
                )
                consecutive_errors = 0
            except asyncio.TimeoutError:
                logger.warning(f"âš ï¸ Timeout (120s): {current_url}")
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    logger.error(f"âŒ Stopped: {max_consecutive_errors} consecutive failures")
                    break
                break
            
            if "error" in result:
                logger.warning(f"âŒ Failed: {result['error']}")
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    break
                current_url = result.get("next_url")
                continue
            elif result.get("date_cutoff_reached"):
                logger.info("ğŸ” Date cutoff reached")
                break
            else:
                formatted_date = ''
                if result.get('date'):
                    date_match = re.search(r'(\d{4})[.\-](\d{1,2})[.\-](\d{1,2})', result['date'])
                    if date_match:
                        formatted_date = f"{date_match.group(1)[2:]}-{date_match.group(2).zfill(2)}-{date_match.group(3).zfill(2)}"
                
                title_clean = sanitize_filename(result.get('title', 'unknown'))
                last_folder = f"({formatted_date}){title_clean}" if formatted_date else title_clean
                
                menus.append({
                    'menu': f"{menu}^{last_folder}" if menu else last_folder,
                    'url': current_url,
                    'murl': result.get('murl')
                })
                datas.append(result)
                total_processed += 1
                
                current_url = result.get("next_url")
                if not current_url:
                    logger.info("ğŸ”— No next link")
                    break
        except Exception as e:
            logger.error(f"âŒ Error: {str(e)}")
            consecutive_errors += 1
            if consecutive_errors >= max_consecutive_errors:
                break
            break
    
    logger.info(f"âœ… Network notice done: {total_processed} items")
    
    return {
        "menus": menus,
        "datas": datas,
        "total_processed": total_processed,
        "status": "completed",
        "message": f"ì´ {total_processed}ê°œ ë„¤íŠ¸ì›Œí¬ ê³µì§€ì‚¬í•­ ì²˜ë¦¬ ì™„ë£Œ"
    }


# í•¸ë“¤ëŸ¬ ë“±ë¡
register_page_handler(
    r'https?://inside\.kt\.com/html/notice/net_notice_list\.html',
    handle_network_notice_main
)




