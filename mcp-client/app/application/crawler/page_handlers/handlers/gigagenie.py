"""
ê¸°ê°€ì§€ë‹ˆ ê´€ë ¨ í•¸ë“¤ëŸ¬

ê¸°ê°€ì§€ë‹ˆ ì„œë¹„ìŠ¤ ìƒì„¸, FAQ, ë‰´ìŠ¤ ëª©ë¡ ì²˜ë¦¬
"""

import logging
import re
from typing import Any, Dict, Optional

from playwright.async_api import async_playwright
from markdownify import markdownify as md

from ..handler_registry import register_page_handler
from ..utils import to_gigagenie_murl, smart_goto

logger = logging.getLogger(__name__)


def clean_img_alt(md_text: str) -> str:
    """altì— <ê°€ í¬í•¨ëœ ê²½ìš° altë¥¼ ë¹„ì›€"""
    def repl(match):
        alt = match.group(1)
        url = match.group(2)
        if '<' in alt:
            return f"![]({url})"
        else:
            return match.group(0)
    return re.sub(r'!\[(.*?)\]\((.*?)\)', repl, md_text, flags=re.DOTALL)


async def handle_gigagenie_detail(
    url: str, 
    fclient: Any = None, 
    menu: Optional[str] = None
) -> Dict[str, Any]:
    """
    ê¸°ê°€ì§€ë‹ˆ ì„œë¹„ìŠ¤ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
    - 2ëìŠ¤ ë²„íŠ¼ë“¤ì„ ëª¨ë‘ ìˆœíšŒí•˜ë©° í´ë¦­
    - ê° ë²„íŠ¼ í´ë¦­ í›„ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œ
    """
    logger.info(f"Gigagenie detail page processing started: {url}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        response = await smart_goto(page, url, wait_for_selector="#depth2Level", timeout=30000)
        
        status_code = response.status if response else None
        if status_code and status_code >= 400:
            logger.error(f"âŒ Gigagenie detail ({url}): HTTP {status_code} error")

        # 2ëìŠ¤ ë²„íŠ¼ ëª©ë¡ ì¶”ì¶œ
        buttons = await page.query_selector_all("#depth2Level li button")
        markdown_content = ""
        html_content = ""
        
        if buttons and len(buttons) > 0:
            tab_infos = []
            for btn in buttons:
                span = await btn.query_selector("span")
                tab_name = (await span.inner_text()).strip() if span else (await btn.inner_text()).strip()
                tab_infos.append({"button": btn, "tab_name": tab_name})

            for tab in tab_infos:
                btn = tab["button"]
                tab_name = tab["tab_name"]
                try:
                    await btn.click()
                    await page.wait_for_timeout(1200)
                    content_div = await page.query_selector("div.fjbInnerTabBox[class*='fjbTabCon'][class~='on']")
                    if content_div:
                        html = await content_div.inner_html()
                        md_text = md(html)
                        md_text = clean_img_alt(md_text)
                        markdown_content += f"# {tab_name}\n\n{md_text}\n\n"
                        html_content += f"<h1>{tab_name}</h1>\n{html}\n\n"
                    else:
                        markdown_content += f"# {tab_name}\n\n(ë‚´ìš© ì—†ìŒ)\n\n"
                        html_content += f"<h1>{tab_name}</h1>\n(ë‚´ìš© ì—†ìŒ)\n\n"
                except Exception as e:
                    logger.warning(f"âš ï¸ Tab '{tab_name}' click/extraction failed: {str(e)}")
                    markdown_content += f"# {tab_name}\n\n(íƒ­ ì¶”ì¶œ ì‹¤íŒ¨)\n\n"
                    html_content += f"<h1>{tab_name}</h1>\n(íƒ­ ì¶”ì¶œ ì‹¤íŒ¨)\n\n"
        else:
            # depth2Levelì´ ì—†ëŠ” ê²½ìš°: ê¸°ë³¸ ì½˜í…ì¸ ë§Œ ì¶”ì¶œ
            content_div = await page.query_selector("div.fjbInnerTabBox[class*='fjbTabCon'][class~='on']")
            if not content_div:
                content_divs = await page.query_selector_all("div.fjbInnerTabBox[class*='fjbTabCon']")
                content_div = content_divs[0] if content_divs else None
            if content_div:
                html = await content_div.inner_html()
                md_text = md(html)
                md_text = clean_img_alt(md_text)
                markdown_content += f"# ê¸°ë³¸ ì½˜í…ì¸ \n\n{md_text}\n\n"
                html_content += f"<h1>ê¸°ë³¸ ì½˜í…ì¸ </h1>\n{html}\n\n"
            else:
                markdown_content += f"# ê¸°ë³¸ ì½˜í…ì¸ \n\n(ë‚´ìš© ì—†ìŒ)\n\n"
                html_content += f"<h1>ê¸°ë³¸ ì½˜í…ì¸ </h1>\n(ë‚´ìš© ì—†ìŒ)\n\n"
        
        await browser.close()

    logger.info(f"âœ… Gigagenie detail page completed: {len(markdown_content)} chars")

    return {
        "url": url,
        "murl": to_gigagenie_murl(url),
        "markdown": markdown_content.strip(),
        "html": html_content.strip(),
        "special_processed": True,
        "playwright_processed": True
    }


async def handle_gigagenie_faq_playwright(url: str, fclient: Any) -> Dict[str, Any]:
    """
    ê¸°ê°€ì§€ë‹ˆ ìì£¼í•˜ëŠ”ì§ˆë¬¸ ì „ì²´ í˜ì´ì§€ FAQ ì¶”ì¶œ
    - ìƒí’ˆë³„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ê° ìƒí’ˆì˜ FAQ ì¶”ì¶œ
    - í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬ (selectFaqList í•¨ìˆ˜ ì‚¬ìš©)
    """
    logger.info(f"Gigagenie FAQ processing started: {url}")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        response = await page.goto(url, wait_until="domcontentloaded", timeout=60000)
        
        status_code = response.status if response else None
        
        # ë™ì  ë¡œë”© ëŒ€ê¸°: FAQ ëª©ë¡ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            await page.wait_for_selector('.faq-list, .board-list, tbody tr', timeout=15000)
            logger.info("âœ… FAQ list loaded")
        except Exception as e:
            logger.warning(f"âš ï¸ FAQ list not loaded: {e}")
        await page.wait_for_timeout(2000)
        if status_code and status_code >= 400:
            logger.error(f"âŒ Gigagenie FAQ ({url}): HTTP {status_code} error")
        
        try:
            await page.wait_for_selector("button[class*='fjbCard']", timeout=30000)
            logger.info("FAQ page loading completed")
        except Exception as e:
            logger.warning(f"âš ï¸ FAQ page loading wait failed: {e}")

        # ìƒí’ˆ ë²„íŠ¼ ëª©ë¡ ì¶”ì¶œ
        product_buttons = await page.query_selector_all("button[class*='fjbCard']")
        logger.info(f"ğŸ” Total {len(product_buttons)} product buttons found")
        
        all_qa_list = []
        
        for product_idx in range(len(product_buttons)):
            try:
                # í•­ìƒ ìµœì‹  ë²„íŠ¼ í•¸ë“¤ë¡œ ì¬ì¡°íšŒ (DOM ë³€ê²½ ëŒ€ì‘)
                product_buttons = await page.query_selector_all("button[class*='fjbCard']")
                button = product_buttons[product_idx]
                
                # ìƒí’ˆëª… ì¶”ì¶œ
                product_name = await button.get_attribute("id-name")
                if not product_name:
                    product_name = await button.inner_text()
                    product_name = product_name.replace('\n', ' ').strip()
                
                logger.info(f"ğŸ” Product {product_idx + 1}/{len(product_buttons)} processing: {product_name}")
                
                # ìƒí’ˆ ë²„íŠ¼ í´ë¦­
                await button.click()
                await page.wait_for_timeout(2000)
                
                # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
                page_num = 1
                max_pages = 50
                seen_questions = set()
                
                while page_num <= max_pages:
                    # Q/A ì¶”ì¶œ
                    qa_items = await page.query_selector_all("ul#faqList li")
                    logger.info(f"  Page {page_num}: {len(qa_items)} FAQ items found")
                    
                    if not qa_items:
                        break
                    
                    for qa in qa_items:
                        try:
                            q_elem = await qa.query_selector("a.fjbQuestion")
                            if q_elem:
                                question = (await q_elem.inner_text()).strip()
                                
                                # ì¤‘ë³µ ì²´í¬
                                if question in seen_questions:
                                    continue
                                seen_questions.add(question)
                                
                                # ì§ˆë¬¸ í´ë¦­í•˜ì—¬ ë‹µë³€ í‘œì‹œ
                                await q_elem.click()
                                await page.wait_for_timeout(500)
                                
                                # ë‹µë³€ ì¶”ì¶œ
                                a_elem = await qa.query_selector("div.fjbAnser")
                                answer = ""
                                if a_elem:
                                    answer_html = await a_elem.inner_html()
                                    answer = md(answer_html).strip()
                                
                                all_qa_list.append({
                                    "product": product_name,
                                    "question": question,
                                    "answer": answer
                                })
                        except Exception as e:
                            logger.warning(f"âš ï¸ Q/A extraction failed: {e}")
                    
                    # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸ ë° ì´ë™ (selectFaqList í•¨ìˆ˜ ì‚¬ìš©)
                    next_page_num = page_num + 1
                    try:
                        # 1. onclickì— selectFaqListê°€ ìˆëŠ” ë§í¬ ì°¾ê¸°
                        next_page_selector = f"a[onclick*='selectFaqList({next_page_num})']"
                        next_page_link = await page.query_selector(next_page_selector)
                        
                        if next_page_link and await next_page_link.is_visible():
                            logger.info(f"  Navigating to page {next_page_num} (link click)")
                            await next_page_link.click()
                            await page.wait_for_timeout(3000)
                            page_num = next_page_num
                        else:
                            # 2. JavaScript í•¨ìˆ˜ ì§ì ‘ ì‹¤í–‰
                            try:
                                await page.evaluate(f"selectFaqList({next_page_num})")
                                await page.wait_for_timeout(3000)
                                
                                # ì‹¤ì œë¡œ í˜ì´ì§€ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                new_qa_items = await page.query_selector_all("ul#faqList li")
                                if new_qa_items:
                                    logger.info(f"  Page {next_page_num} navigation successful (JS execution)")
                                    page_num = next_page_num
                                else:
                                    logger.info(f"  Page {next_page_num} not found. Moving to next product")
                                    break
                            except Exception as e:
                                logger.info(f"  Page {next_page_num} navigation failed: {str(e)}")
                                break
                    except Exception as e:
                        logger.info(f"  Pagination processing failed: {str(e)}")
                        break
                        
            except Exception as e:
                logger.warning(f"âš ï¸ Product FAQ processing failed: {e}")
        
        await browser.close()
    
    logger.info(f"âœ… Gigagenie FAQ completed: {len(all_qa_list)} Q/A")
    
    # ê²°ê³¼ ë§ˆí¬ë‹¤ìš´ ìƒì„±
    markdown_content = "# ê¸°ê°€ì§€ë‹ˆ ìì£¼í•˜ëŠ”ì§ˆë¬¸\n\n"
    markdown_content += f"ì´ {len(all_qa_list)}ê°œ FAQ\n\n---\n\n"
    
    html_content = f"<h1>ê¸°ê°€ì§€ë‹ˆ ìì£¼í•˜ëŠ”ì§ˆë¬¸</h1>\n<p>ì´ {len(all_qa_list)}ê°œ FAQ</p>\n<hr/>\n"
    
    current_product = ""
    for qa in all_qa_list:
        if qa["product"] != current_product:
            current_product = qa["product"]
            markdown_content += f"\n## {current_product}\n\n"
            html_content += f"<h2>{current_product}</h2>\n"
        
        markdown_content += f"### Q: {qa['question']}\n\n**A:** {qa['answer']}\n\n---\n\n"
        html_content += f"<h3>Q: {qa['question']}</h3>\n<p><strong>A:</strong> {qa['answer']}</p>\n<hr/>\n"
    
    # FAQê°€ ì—†ëŠ” ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
    if not all_qa_list:
        markdown_content += "\n> FAQë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        html_content += "<p><em>FAQë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</em></p>\n"

    return {
        "url": url,
        "title": "ê¸°ê°€ì§€ë‹ˆ ìì£¼í•˜ëŠ”ì§ˆë¬¸",
        "markdown": markdown_content.strip(),
        "html": html_content.strip(),
        "qa_list": all_qa_list,
        "qa_count": len(all_qa_list),
        "special_processed": True,
        "playwright_processed": True
    }


# í•¸ë“¤ëŸ¬ ë“±ë¡
register_page_handler(
    r'https?://gigagenie\.kt\.com/whyGenieServiceDetail\.do\?serviceCate=.*',
    handle_gigagenie_detail
)

register_page_handler(
    r'https?://gigagenie\.kt\.com/whyGenieFaq\.do.*',
    handle_gigagenie_faq_playwright
)


async def handle_gigagenie_news_list(url: str, fclient: Any, menu: Optional[str] = None) -> Dict[str, Any]:
    """
    ê¸°ê°€ì§€ë‹ˆ ì§€ë‹ˆì†Œì‹ ëª©ë¡ Playwright í•¸ë“¤ëŸ¬
    - "ë”ë³´ê¸°" ë²„íŠ¼ì„ ëê¹Œì§€ í´ë¦­í•´ ì „ì²´ ê²Œì‹œë¬¼ì„ ë…¸ì¶œ
    - ëª©ë¡ì—ì„œ seq, ì œëª©ì„ ì¶”ì¶œí•´ ìƒì„¸ URLì„ êµ¬ì„±
    - ê° ìƒì„¸ í˜ì´ì§€ì—ì„œ ì œëª©, ë‚ ì§œ, ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ì—¬ Markdown/HTML ìƒì„±
    """
    import asyncio
    from playwright.async_api import TimeoutError as PlaywrightTimeoutError
    
    logger.info(f"ğŸ”— Gigagenie News List handler entered: url={url}, menu={menu}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        response = await page.goto(url, wait_until="domcontentloaded", timeout=40000)

        status_code = response.status if response else None
        
        # ë™ì  ë¡œë”© ëŒ€ê¸°: ë‰´ìŠ¤ ëª©ë¡ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            await page.wait_for_selector('.news-list, .board-list, tbody tr', timeout=15000)
            logger.info("âœ… News list loaded")
        except Exception as e:
            logger.warning(f"âš ï¸ News list not loaded: {e}")
        await page.wait_for_timeout(2000)
        if status_code:
            if status_code >= 400:
                logger.error(f"âŒ Gigagenie News List ({url}): HTTP {status_code} error")
            elif status_code >= 300:
                logger.warning(f"âš ï¸ Gigagenie News List ({url}): HTTP {status_code} redirect")
            else:
                logger.info(f"âœ… Gigagenie News List ({url}): HTTP {status_code} success")

        load_more_selector = "button#btn_more"
        try:
            while True:
                load_more_button = await page.query_selector(load_more_selector)
                if not load_more_button:
                    logger.info("Load More button not found, assuming all posts loaded")
                    break
                if not await load_more_button.is_visible():
                    logger.info("Load More button hidden, loading complete")
                    break
                if not await load_more_button.is_enabled():
                    logger.info("Load More button disabled, loading complete")
                    break
                try:
                    await load_more_button.click()
                except PlaywrightTimeoutError:
                    logger.warning("âš ï¸ Load More button click timeout, assuming loading complete")
                    break
                logger.info("Load More button clicked, waiting for additional posts")
                await page.wait_for_timeout(2000)
        except PlaywrightTimeoutError as timeout_err:
            logger.warning(f"âš ï¸ Load More button processing timeout: {str(timeout_err)}")
        except Exception as e:
            logger.warning(f"âš ï¸ Load More button processing error: {str(e)}")

        card_selector = "ul#bloglist li"
        try:
            await page.wait_for_selector(card_selector, timeout=5000)
        except PlaywrightTimeoutError:
            logger.warning("âš ï¸ Gigagenie News cards not loaded within timeout")
        except Exception as wait_err:
            logger.warning(f"âš ï¸ Exception waiting for Gigagenie News cards: {wait_err}")
        cards = await page.query_selector_all(card_selector)
        logger.info(f"ğŸ” {len(cards)} Gigagenie News cards found")

        base_menu = menu or "ì§€ë‹ˆì†Œì‹"
        datas = []
        menus = []

        semaphore = asyncio.Semaphore(5)

        async def process_detail(detail_url: str, parent_menu: str, original_idx: int):
            async with semaphore:
                detail_page = await browser.new_page()

                try:
                    detail_response = await detail_page.goto(detail_url, wait_until="domcontentloaded", timeout=40000)

                    detail_status = detail_response.status if detail_response else None
                    
                    # ìƒì„¸ í˜ì´ì§€ ì½˜í…ì¸  ëŒ€ê¸°
                    try:
                        await detail_page.wait_for_selector('.content, .detail-content', timeout=10000)
                    except Exception:
                        pass
                    await detail_page.wait_for_timeout(2000)
                    if detail_status:
                        if detail_status >= 400:
                            logger.error(f"âŒ Gigagenie News detail ({detail_url}): HTTP {detail_status} error")
                        elif detail_status >= 300:
                            logger.warning(f"âš ï¸ Gigagenie News detail ({detail_url}): HTTP {detail_status} redirect")
                        else:
                            logger.info(f"âœ… Gigagenie News detail ({detail_url}): HTTP {detail_status} success")

                    title_selector = "h3.cfmOllehNewsTitle div.inner"
                    date_selector = "h3.cfmOllehNewsTitle div.inner span.date"

                    title_element = await detail_page.query_selector(title_selector)
                    raw_title = (await title_element.inner_text()) if title_element else ""
                    title_clean = re.sub(r"\s+", " ", raw_title).strip()

                    date_element = await detail_page.query_selector(date_selector)
                    raw_date = (await date_element.inner_text()) if date_element else ""
                    date_text = raw_date.strip()

                    startdate = "1900-01-01"
                    if date_text:
                        m = re.match(r"(\d{2})\.(\d{2})\.(\d{2})", date_text)
                        if m:
                            year = int(m.group(1))
                            year += 2000 if year < 70 else 1900
                            startdate = f"{year}-{m.group(2)}-{m.group(3)}"

                    content_selectors = [
                        "div.cfmOllehNewsCont",
                        "div.fjbNewsArea",
                        "div[style*='background']"
                    ]
                    inner_html = ""
                    for selector in content_selectors:
                        elem = await detail_page.query_selector(selector)
                        if elem:
                            inner_html = await elem.inner_html()
                            if inner_html and inner_html.strip():
                                break

                    if not inner_html:
                        logger.warning(f"âš ï¸ Main content not found: {detail_url}")

                    markdown_content = md(inner_html, heading_style="ATX") if inner_html else ""
                    html_content = inner_html or ""

                    # íŒŒì¼ëª… ì•ˆì „ ë³€í™˜
                    title_for_menu = re.sub(r'[\\/*?:"<>|]', '', title_clean) if title_clean else "ì§€ë‹ˆì†Œì‹"
                    final_menu = f"{parent_menu}^{title_for_menu}" if parent_menu else title_for_menu

                    datas.append({
                        "url": detail_url,
                        "title": title_clean,
                        "date": date_text,
                        "startdate": startdate,
                        "markdown": markdown_content,
                        "html": html_content,
                        "status_code": detail_status,
                        "special_processed": True,
                        "playwright_processed": True,
                        "murl": to_gigagenie_murl(detail_url),
                        "original_index": original_idx
                    })

                    menus.append({
                        "menu": final_menu,
                        "url": detail_url,
                        "mobile_url": detail_url,
                        "murl": to_gigagenie_murl(detail_url),
                        "original_index": original_idx
                    })

                    logger.info(f"âœ… Gigagenie News detail extracted: title='{title_clean}', startdate='{startdate}'")

                except Exception as detail_err:
                    logger.error(f"âŒ Gigagenie News detail processing failed ({detail_url}): {str(detail_err)}")
                    datas.append({
                        "url": detail_url,
                        "title": "",
                        "date": "",
                        "startdate": "0000-00-00",
                        "markdown": "",
                        "html": "",
                        "error": str(detail_err),
                        "special_processed": True,
                        "playwright_processed": True,
                        "murl": to_gigagenie_murl(detail_url),
                        "original_index": original_idx
                    })
                    menus.append({
                        "menu": parent_menu,
                        "url": detail_url,
                        "mobile_url": detail_url,
                        "murl": to_gigagenie_murl(detail_url),
                        "original_index": original_idx
                    })
                finally:
                    await detail_page.close()

        for idx, card in enumerate(cards):
            try:
                thumbnail_link = await card.query_selector("a.thumbnail")
                if not thumbnail_link:
                    logger.warning("âš ï¸ Thumbnail link missing, skipping card")
                    continue

                onclick_attr = await thumbnail_link.get_attribute("onclick") or ""
                seq_match = re.search(r"goDetPage\((\d+)\)", onclick_attr)
                seq = seq_match.group(1) if seq_match else None

                if seq:
                    detail_url = f"https://gigagenie.kt.com/blog/detail.do?seq={seq}"
                else:
                    href_attr = await thumbnail_link.get_attribute("href") or ""
                    if href_attr.startswith("http"):
                        detail_url = href_attr
                    else:
                        detail_url = f"https://gigagenie.kt.com{href_attr}" if href_attr else ""

                if not detail_url:
                    logger.warning("âš ï¸ Cannot construct detail URL, skipping card")
                    continue

                await process_detail(detail_url, base_menu, idx)

            except Exception as card_err:
                logger.error(f"âŒ Gigagenie News card processing failed: {str(card_err)}")
                continue
        await browser.close()

    logger.info(f"âœ… Gigagenie News List completed: Total {len(datas)} posts")

    return {
        "menus": menus,
        "datas": datas,
        "total_processed": len(datas),
        "status": "completed",
        "message": f"ì´ {len(datas)}ê°œ ì§€ë‹ˆì†Œì‹ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì™„ë£Œ",
        "special_processed": True,
        "playwright_processed": True
    }


register_page_handler(
    r'https?://gigagenie\.kt\.com/whyGenieNews\.do',
    handle_gigagenie_news_list
)
